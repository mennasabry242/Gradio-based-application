# -*- coding: utf-8 -*-
"""code.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1KwtPF_fJzFP5dRPSYT_2YMnlUQmz10ar
"""

!pip install torch torchvision transformers accelerate gradio

import gradio as gr
import torch
from PIL import Image
from transformers import AutoProcessor, LlavaForConditionalGeneration, AutoTokenizer, AutoModelForCausalLM

# ----------- CONFIG -----------
caption_model_id = "llava-hf/llava-1.5-7b-hf"
code_model_id = "deepseek-ai/deepseek-coder-1.3b-instruct"
tokenizer = AutoTokenizer.from_pretrained(code_model_id, trust_remote_code=True)

# ----------- IMAGE DESCRIPTION -----------
def describe_image(image):
    try:
        processor = AutoProcessor.from_pretrained(caption_model_id)
        model = LlavaForConditionalGeneration.from_pretrained(
            caption_model_id, torch_dtype=torch.float16, device_map="auto"
        ).eval()

        prompt = "<image>\nDescribe the image."
        image = image.convert("RGB")
        inputs = processor(text=prompt, images=image, return_tensors="pt").to(model.device)
        output = model.generate(**inputs, max_new_tokens=100)
        caption = processor.batch_decode(output, skip_special_tokens=True)[0]

        del model
        torch.cuda.empty_cache()

        return caption
    except Exception as e:
        torch.cuda.empty_cache()
        return f"Error generating description: {e}"

# ----------- CODE GENERATION -----------
def generate_code_only(task_description, temperature=0.7, top_p=0.9, max_tokens=150):
    try:
        model = AutoModelForCausalLM.from_pretrained(
            code_model_id,
            trust_remote_code=True,
            torch_dtype=torch.float16,
            device_map="auto"
        ).eval()

        prompt = (
            f"Write only the Python function that solves the following task. "
            f"Do not add comments, explanations, or markdown.\n\n"
            f"Task: {task_description}\n\n"
            f"Code:\n"
        )
        inputs = tokenizer(prompt, return_tensors="pt").to(model.device)
        outputs = model.generate(
            **inputs,
            max_new_tokens=max_tokens,
            temperature=temperature,
            top_p=top_p,
            pad_token_id=tokenizer.eos_token_id,
            eos_token_id=tokenizer.eos_token_id,
            do_sample=True
        )
        text = tokenizer.decode(outputs[0], skip_special_tokens=True)

        del model
        torch.cuda.empty_cache()

        return text.split("Code:")[-1].strip() if "Code:" in text else text.strip()
    except Exception as e:
        torch.cuda.empty_cache()
        return f"Error generating code: {e}"

# ----------- COMBINED FUNCTION -----------
def generate_both(selected, image, task_prompt, temperature, top_p, max_tokens):
    caption, code = "", ""

    if "Image Description" in selected and image:
        caption = describe_image(image)

    if "Python Code" in selected and task_prompt.strip():
        code = generate_code_only(task_prompt, temperature, top_p, max_tokens)

    return caption, code

# ----------- GRADIO INTERFACE -----------
with gr.Blocks() as demo:
    gr.Markdown("## ðŸ”„ Unified Image Description & Code Generator")

    with gr.Row():
        task_selector = gr.CheckboxGroup(
            choices=["Image Description", "Python Code"],
            label="Select Tasks",
            value=["Image Description"]
        )

    with gr.Row():
        image_input = gr.Image(type="pil", label="Upload Image")
        task_prompt = gr.Textbox(label="Task Prompt (for code generation)", lines=2, placeholder="E.g., Write a function to reverse a string.")

    with gr.Row():
        temperature = gr.Slider(0.1, 1.0, value=0.7, step=0.05, label="Temperature")
        top_p = gr.Slider(0.1, 1.0, value=0.9, step=0.05, label="Top-p")
        max_tokens = gr.Slider(50, 300, value=150, step=10, label="Max Tokens")

    with gr.Row():
        run_button = gr.Button("Generate")

    with gr.Row():
        caption_output = gr.Textbox(label="Image Description", lines=5)
        code_output = gr.Textbox(label="Generated Python Code", lines=15)

    run_button.click(
        fn=generate_both,
        inputs=[task_selector, image_input, task_prompt, temperature, top_p, max_tokens],
        outputs=[caption_output, code_output]
    )

if __name__ == "__main__":
    demo.launch()